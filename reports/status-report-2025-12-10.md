# Homelab Status Report - 2025-12-10

## Executive Summary
**Overall Status**: 游리 **YELLOW**

**Summary**: The homelab is operationally healthy with all 10 nodes running and 32 applications synced. However, Ceph storage shows warnings related to slow OSD operations and low monitor disk space that require attention. All critical services are functional and certificates are valid through 2026.

## Detailed Status

| Layer | Status | Key Findings |
|-------|:------:|--------------|
| **Metal** | 游릭 | - All 10 nodes online and Ready (3 masters, 7 workers)<br>- CPU usage: 2-17% across nodes (healthy)<br>- Memory usage: 5-34% across nodes (healthy)<br>- All nodes on Fedora Linux 39, k3s v1.33.6 |
| **System** | 游리 | - All system pods Running/Completed<br>- Cilium CNI healthy (10 pods running)<br>- **WARNING**: Ceph HEALTH_WARN (slow OSD ops, low mon space)<br>- Storage: 193GB used / 3.4TB available (5.7% used)<br>- 7 OSDs operational |
| **Platform** | 游릭 | - ArgoCD: 32/32 applications Synced+Healthy<br>- Ingress NGINX running (1/1)<br>- Cert-Manager operational (3/3 pods)<br>- All certificates valid until 2026 (earliest: 2026-01-11)<br>- Monitoring functional |
| **Apps** | 游릭 | - All user apps running: emby, gitea, sonarr, radarr, ollama, openwebui, sabnzbd, searxng<br>- Top memory consumer: emby (3971Mi)<br>- Prometheus using 2099Mi<br>- All apps stable with minimal restarts (1 restart in last 8h) |

## Issues & Recommendations

### Warnings (Yellow)
- [ ] **Issue**: Ceph HEALTH_WARN - 1 OSD experiencing slow operations in BlueStore
  - **Fix**: Investigate OSD performance. Check disk health on affected node. Consider: `ceph osd df`, `ceph osd perf`, check for disk I/O bottlenecks
  - **Timeline**: Investigate within 48 hours. Not critical but indicates potential hardware degradation
  
- [ ] **Issue**: Monitors d, f, g are low on available space
  - **Fix**: Check monitor disk usage and clean up old metadata. Default mon data is stored on root partition - verify `/var/lib/rook` space
  - **Timeline**: Address within 1 week before it becomes critical

### Observations (Green)
- Cluster uptime is excellent - most nodes running 291 days
- ArgoCD GitOps fully operational with 100% sync status
- Certificate renewal automation working well (all certs > 30 days from expiry)
- Resource utilization is healthy with plenty of headroom
- Recent cluster restart 8h ago (evidenced by pod ages) - all services recovered successfully
- Application diversity: 32 distinct applications across monitoring, media, AI/ML, DevOps, and search workloads

## Verification Data

- **Nodes**: 10 Online / 10 Total
  - **Masters**: charmander (10.0.50.121), squirtle (10.0.50.122), bulbasaur (10.0.50.123)
  - **Workers**: pikachu, chikorita, cyndaquil, totodile, growlithe, arcanine, sprigatito
- **Storage**: 5.7% Used (193GB used, 3.2TB free of 3.4TB total)
- **Top Resource Consumers**: 
  - Memory: emby (3971Mi), prometheus (2099Mi), openwebui (403Mi)
  - CPU: Various OSDs (17-29m each), cilium-kvbrp (37m)
- **Ceph Status**: HEALTH_WARN
  - 7 OSDs up and in
  - 3 monitors (d, f, g)
  - 2 MGRs (b active, a standby)
  - 1/1 MDS daemons up, 1 hot standby
- **ArgoCD**: 32 Synced / 0 OutOfSync / 32 Total Apps
- **Certificate Expiry**: Shortest remaining: ~1 month (openwebui: 2026-01-11), most until Jan-Mar 2026
- **Kubernetes Version**: v1.33.6+k3s1
- **Container Runtime**: containerd://2.1.5-k3s1.33
- **CNI**: Cilium (10 pods + 1 operator)

## Next Steps

1. **Immediate**: Investigate Ceph slow OSD operations
   ```bash
   # SSH to controller, then to master node
   ssh brimdor@10.0.50.120
   ssh root@10.0.50.121
   k3s kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph osd df
   k3s kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph osd perf
   ```

2. **This Week**: Check and clean up monitor disk space
   ```bash
   # Check mon data usage
   k3s kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph df detail
   # Check actual filesystem usage on mon pods
   k3s kubectl -n rook-ceph exec -it rook-ceph-mon-d-<podname> -- df -h
   ```

3. **Ongoing**: Monitor Ceph health daily until warnings are resolved

---
**Report Generated**: 2025-12-10 00:10 CST  
**Generated by**: Antigravity  
**Report File**: `reports/status-report-2025-12-10.md`
